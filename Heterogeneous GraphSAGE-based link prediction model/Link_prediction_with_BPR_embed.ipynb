{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz1i9ZqDyzGK",
        "outputId": "30e79fcc-99dc-43ab-e094-2a624e9e130b"
      },
      "outputs": [],
      "source": [
        "pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZg3UwPjnrVJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch_geometric.data import HeteroData\n",
        "import torch_geometric.transforms as T\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, GATConv, to_hetero, LayerNorm,BatchNorm\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch.nn import Linear, Dropout\n",
        "import torch.optim as optim\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93YKzJ77pLpn"
      },
      "outputs": [],
      "source": [
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class LinkPredictor(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(LinkPredictor, self).__init__()\n",
        "        self.gnn = GraphSAGE(in_channels, hidden_channels, out_channels)\n",
        "        self.gnn = to_hetero(self.gnn, data.metadata())\n",
        "\n",
        "    def encode(self, x_dict, edge_index_dict):\n",
        "        return self.gnn(x_dict, edge_index_dict)\n",
        "\n",
        "    def decode(self, z_dict, edge_label_index):\n",
        "        user_embeddings = z_dict['user']\n",
        "        item_embeddings = z_dict['movie']\n",
        "        user_emb = user_embeddings[edge_label_index[0]]\n",
        "        item_emb = item_embeddings[edge_label_index[1]]\n",
        "\n",
        "        similarity = F.cosine_similarity(user_emb, item_emb, dim=1)\n",
        "        return similarity.sigmoid()\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "        z_dict = self.encode(x_dict, edge_index_dict)\n",
        "        return self.decode(z_dict, edge_label_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LinkPredictor(in_channels = 10, hidden_channels=32, out_channels = 10)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNZ9H5_4cFDP"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_csv('data_movie_1m_2nd.csv')\n",
        "df2 = pd.read_csv('data_movie_1m_1st.csv')\n",
        "df3 = pd.read_csv('data_movie_1m4_3rd.csv')\n",
        "\n",
        "df = pd.concat([df1, df2, df3], ignore_index=True)\n",
        "\n",
        "df_movie = pd.read_csv('df_movie.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-74xaS6bKRc"
      },
      "outputs": [],
      "source": [
        "df_movie['rating'] = df['sentiment_label_int']\n",
        "df_movie.rename(columns={'rating': 'sent_score'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ny4R-SHizpW2"
      },
      "outputs": [],
      "source": [
        "df_item_embed = pd.read_csv('item_embeddings_movie_sen10.csv')\n",
        "df_user_embed = pd.read_csv('user_embeddings_movie_sen10.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeDAJ-cLpSki"
      },
      "outputs": [],
      "source": [
        "df_movie = df_movie[df_movie['userID'].isin(df_user_embed['userID'])]\n",
        "df_movie = df_movie[df_movie['itemID'].isin(df_item_embed['itemID'])]\n",
        "df_movie = df_movie[df_movie['sent_score'] >= 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uE5IxCdcbvzW"
      },
      "outputs": [],
      "source": [
        "user_movie = df_user_embed['userID'].unique()\n",
        "num_users = df_user_embed.shape[0]\n",
        "user_movie_map = {user_id: i for i, user_id in enumerate(user_movie)}\n",
        "\n",
        "df_user_embed['userID'] = df_user_embed['userID'].map(user_movie_map)\n",
        "df_user_embed.sort_values('userID', inplace=True)\n",
        "user_vectors = df_user_embed.drop(['userID'], axis=1).to_numpy()\n",
        "user_vectors = torch.from_numpy(user_vectors).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeRXg8nMbkSw"
      },
      "outputs": [],
      "source": [
        "movie_ids = df_item_embed['itemID'].unique()\n",
        "num_movies = df_item_embed.shape[0]\n",
        "movie_map = {movie_id: i for i, movie_id in enumerate(movie_ids)}\n",
        "\n",
        "df_item_embed['itemID'] = df_item_embed['itemID'].map(movie_map)\n",
        "df_item_embed.sort_values('itemID', inplace=True)\n",
        "item_vectors = df_item_embed.drop(['itemID'], axis=1).to_numpy()\n",
        "item_vectors = torch.from_numpy(item_vectors).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gImphtgqwr9O"
      },
      "outputs": [],
      "source": [
        "user_movie_ids = df_movie['userID'].map(user_movie_map).to_numpy()\n",
        "item_movie_ids = df_movie['itemID'].map(movie_map).to_numpy()\n",
        "movie_edges_matrix = np.vstack((user_movie_ids, item_movie_ids))\n",
        "movie_edges_matrix = torch.from_numpy(movie_edges_matrix).to(torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_jzLQmdpeFk",
        "outputId": "8b7c9e9d-c938-440a-9a06-dc613774f32f"
      },
      "outputs": [],
      "source": [
        "data = HeteroData()\n",
        "\n",
        "data['user'].x = user_vectors\n",
        "data['movie'].x = item_vectors\n",
        "\n",
        "data['user', 'rates', 'movie'].edge_index = movie_edges_matrix\n",
        "\n",
        "data = T.ToUndirected()(data)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Lkkpc7wp9-s"
      },
      "outputs": [],
      "source": [
        "def train(loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        edge_label = data['user', 'rates', 'movie'].edge_label\n",
        "        edge_label_index = data['user', 'rates', 'movie'].edge_label_index\n",
        "\n",
        "        out = model(data.x_dict, data.edge_index_dict, edge_label_index)\n",
        "        loss = F.binary_cross_entropy_with_logits(out, edge_label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        all_labels.extend(edge_label.cpu().numpy())\n",
        "        all_preds.extend(torch.sigmoid(out).detach().cpu().numpy())\n",
        "\n",
        "    auc_score = roc_auc_score(all_labels, all_preds)\n",
        "    return total_loss / len(loader.dataset), auc_score\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            edge_label = data['user', 'rates', 'movie'].edge_label\n",
        "            edge_label_index = data['user', 'rates', 'movie'].edge_label_index\n",
        "\n",
        "            out = model(data.x_dict, data.edge_index_dict, edge_label_index)\n",
        "            loss = F.binary_cross_entropy_with_logits(out, edge_label)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            all_labels.extend(edge_label.cpu().numpy())\n",
        "            all_preds.extend(torch.sigmoid(out).detach().cpu().numpy())\n",
        "\n",
        "    auc_score = roc_auc_score(all_labels, all_preds)\n",
        "    return total_loss / len(loader.dataset), auc_score\n",
        "\n",
        "\n",
        "def train_test(train_loader, val_loader, test_loader):\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(1500):\n",
        "        train_loss, train_acc = train(train_loader)\n",
        "        print(f'Epoch: {epoch:03d}, Train Loss: {train_loss}, Train AUC: {train_acc}')\n",
        "\n",
        "        torch.save(model.state_dict(), f'model_epoch_{epoch}.pth')\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "\n",
        "        val_loss, val_acc = evaluate(val_loader)\n",
        "        print(f'Val loss: {val_loss}, Val AUC: {val_acc}')\n",
        "\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        test_loss, test_acc = evaluate(test_loader)\n",
        "        print(f'Test loss: {test_loss}, Test AUC: {test_acc}\\n')\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_accuracies, label='Train AUC')\n",
        "    plt.plot(val_accuracies, label='Validation AUC')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.title('Training and Validation AUC')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a3zF9dbaFkU"
      },
      "outputs": [],
      "source": [
        "transform = T.RandomLinkSplit(\n",
        "    num_val=0.1,\n",
        "    num_test=0.1,\n",
        "    disjoint_train_ratio=0.5,\n",
        "    neg_sampling_ratio=1.0,\n",
        "    add_negative_train_samples=True,\n",
        "    edge_types=(\"user\", \"rates\", \"movie\"),\n",
        "    rev_edge_types=(\"movie\", \"rev_rates\", \"user\"),\n",
        ")\n",
        "\n",
        "train_data, val_data, test_data = transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgLCFCIv1QBe",
        "outputId": "6c08c281-5305-4717-e4f4-181d8de57fa6"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader([train_data], batch_size=512, shuffle=True)\n",
        "val_loader = DataLoader([val_data], batch_size=512, shuffle=False)\n",
        "test_loader = DataLoader([test_data], batch_size=512, shuffle=False)\n",
        "train_test(train_loader, val_loader, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5ziEP1X1RzB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
